var graphql = require('graphql');

var wonka = require('wonka');

const generateErrorMessage = (networkErr, graphQlErrs) => {
  let error = '';
  if (networkErr) return `[Network] ${networkErr.message}`;

  if (graphQlErrs) {
    for (const err of graphQlErrs) {
      if (error) error += '\n';
      error += `[GraphQL] ${err.message}`;
    }
  }

  return error;
};

const rehydrateGraphQlError = error => {
  if (typeof error === 'string') {
    return new graphql.GraphQLError(error);
  } else if (typeof error === 'object' && error.message) {
    return new graphql.GraphQLError(error.message, error.nodes, error.source, error.positions, error.path, error, error.extensions || {});
  } else {
    return error;
  }
};
/** An error which can consist of GraphQL errors and Network errors. */


class CombinedError extends Error {
  constructor(input) {
    const normalizedGraphQLErrors = (input.graphQLErrors || []).map(rehydrateGraphQlError);
    const message = generateErrorMessage(input.networkError, normalizedGraphQLErrors);
    super(message);
    this.name = 'CombinedError';
    this.message = message;
    this.graphQLErrors = normalizedGraphQLErrors;
    this.networkError = input.networkError;
    this.response = input.response;
  }

  toString() {
    return this.message;
  }

} // When we have separate strings it's useful to run a progressive
// version of djb2 where we pretend that we're still looping over
// the same string


const phash = (h, x) => {
  for (let i = 0, l = x.length | 0; i < l; i++) h = (h << 5) + h + x.charCodeAt(i);

  return h | 0;
}; // This is a djb2 hashing function


const hash = x => phash(5381 | 0, x) >>> 0;

const seen = new Set();
const cache = new WeakMap();

const stringify = x => {
  if (x === null || seen.has(x)) {
    return 'null';
  } else if (typeof x !== 'object') {
    return JSON.stringify(x) || '';
  } else if (x.toJSON) {
    return stringify(x.toJSON());
  } else if (Array.isArray(x)) {
    let out = '[';

    for (let value of x) {
      if (out !== '[') out += ',';
      value = stringify(value);
      out += value.length > 0 ? value : 'null';
    }

    out += ']';
    return out;
  }

  const keys = Object.keys(x).sort();

  if (!keys.length && x.constructor && x.constructor !== Object) {
    const key = cache.get(x) || Math.random().toString(36).slice(2);
    cache.set(x, key);
    return `{"__key":"${key}"}`;
  }

  seen.add(x);
  let out = '{';

  for (const key of keys) {
    const value = stringify(x[key]);

    if (value) {
      if (out.length > 1) out += ',';
      out += stringify(key) + ':' + value;
    }
  }

  seen.delete(x);
  out += '}';
  return out;
};

const stringifyVariables = x => {
  seen.clear();
  return stringify(x);
};

const GRAPHQL_STRING_RE = /("{3}[\s\S]*"{3}|"(?:\\.|[^"])*")/g;
const REPLACE_CHAR_RE = /([\s,]|#[^\n\r]+)+/g;

const replaceOutsideStrings = (str, idx) => idx % 2 === 0 ? str.replace(REPLACE_CHAR_RE, ' ').trim() : str;

const stringifyDocument = node => {
  let str = (typeof node !== 'string' ? node.loc && node.loc.source.body || graphql.print(node) : node).split(GRAPHQL_STRING_RE).map(replaceOutsideStrings).join('');

  if (typeof node !== 'string') {
    const operationName = 'definitions' in node && getOperationName(node);

    if (operationName) {
      str = `# ${operationName}\n${str}`;
    }

    if (!node.loc) {
      node.loc = {
        start: 0,
        end: str.length,
        source: {
          body: str,
          name: 'gql',
          locationOffset: {
            line: 1,
            column: 1
          }
        }
      };
    }
  }

  return str;
};

const docs = new Map();

const keyDocument = q => {
  let key;
  let query;

  if (typeof q === 'string') {
    key = hash(stringifyDocument(q));
    query = docs.get(key) || graphql.parse(q, {
      noLocation: true
    });
  } else {
    key = q.__key || hash(stringifyDocument(q));
    query = docs.get(key) || q;
  } // Add location information if it's missing


  if (!query.loc) stringifyDocument(query);
  query.__key = key;
  docs.set(key, query);
  return query;
};

const createRequest = (q, vars) => {
  if (!vars) vars = {};
  const query = keyDocument(q);
  return {
    key: phash(query.__key, stringifyVariables(vars)) >>> 0,
    query,
    variables: vars
  };
};
/**
 * Finds the Name value from the OperationDefinition of a Document
 */


const getOperationName = query => {
  for (const node of query.definitions) {
    if (node.kind === graphql.Kind.OPERATION_DEFINITION && node.name) {
      return node.name.value;
    }
  }
};
/**
 * Finds the operation-type
 */


const getOperationType = query => {
  for (const node of query.definitions) {
    if (node.kind === graphql.Kind.OPERATION_DEFINITION) {
      return node.operation;
    }
  }
};

const makeResult = (operation, result, response) => {
  if (!('data' in result) && !('errors' in result) || 'path' in result) {
    throw new Error('No Content');
  }

  return {
    operation,
    data: result.data,
    error: Array.isArray(result.errors) ? new CombinedError({
      graphQLErrors: result.errors,
      response
    }) : undefined,
    extensions: typeof result.extensions === 'object' && result.extensions || undefined,
    hasNext: !!result.hasNext
  };
};

const mergeResultPatch = (prevResult, patch, response) => {
  const result = { ...prevResult
  };
  result.hasNext = !!patch.hasNext;

  if (!('path' in patch)) {
    if ('data' in patch) result.data = patch.data;
    return result;
  }

  if (Array.isArray(patch.errors)) {
    result.error = new CombinedError({
      graphQLErrors: result.error ? [...result.error.graphQLErrors, ...patch.errors] : patch.errors,
      response
    });
  }

  let part = result.data = { ...result.data
  };
  let i = 0;
  let prop;

  while (i < patch.path.length) {
    prop = patch.path[i++];
    part = part[prop] = Array.isArray(part[prop]) ? [...part[prop]] : { ...part[prop]
    };
  }

  Object.assign(part, patch.data);
  return result;
};

const makeErrorResult = (operation, error, response) => ({
  operation,
  data: undefined,
  error: new CombinedError({
    networkError: error,
    response
  }),
  extensions: undefined
});

function makeFetchBody(request) {
  return {
    query: graphql.print(request.query),
    operationName: getOperationName(request.query),
    variables: request.variables || undefined,
    extensions: undefined
  };
}

const makeFetchURL = (operation, body) => {
  const useGETMethod = operation.kind === 'query' && !!operation.context.preferGetMethod;
  if (!useGETMethod || !body) return operation.context.url;
  const url = new URL(operation.context.url);
  const search = url.searchParams;
  if (body.operationName) search.set('operationName', body.operationName);
  if (body.query) search.set('query', body.query.replace(/#[^\n\r]+/g, ' ').trim());
  if (body.variables) search.set('variables', stringifyVariables(body.variables));
  if (body.extensions) search.set('extensions', stringifyVariables(body.extensions));
  const finalUrl = url.toString();

  if (finalUrl.length > 2047) {
    operation.context.preferGetMethod = false;
    return operation.context.url;
  }

  return finalUrl;
};

const makeFetchOptions = (operation, body) => {
  const useGETMethod = operation.kind === 'query' && !!operation.context.preferGetMethod;
  const headers = {
    accept: 'application/graphql+json, application/json'
  };
  if (!useGETMethod) headers['content-type'] = 'application/json';
  const extraOptions = (typeof operation.context.fetchOptions === 'function' ? operation.context.fetchOptions() : operation.context.fetchOptions) || {};
  if (extraOptions.headers) for (const key in extraOptions.headers) headers[key.toLowerCase()] = extraOptions.headers[key];
  return { ...extraOptions,
    body: !useGETMethod && body ? JSON.stringify(body) : undefined,
    method: useGETMethod ? 'GET' : 'POST',
    headers
  };
};

const decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder() : null;
const jsonHeaderRe = /content-type:[^\r\n]*application\/json/i;
const boundaryHeaderRe = /boundary="?([^=";]+)"?/i; // NOTE: We're avoiding referencing the `Buffer` global here to prevent
// auto-polyfilling in Webpack

const toString = input => input.constructor.name === 'Buffer' ? input.toString() : decoder.decode(input);

const makeFetchSource = (operation, url, fetchOptions) => {
  const maxStatus = fetchOptions.redirect === 'manual' ? 400 : 300;
  const fetcher = operation.context.fetch;
  return wonka.make(({
    next,
    complete
  }) => {
    const abortController = typeof AbortController !== 'undefined' ? new AbortController() : null;

    if (abortController) {
      fetchOptions.signal = abortController.signal;
    }

    let hasResults = false; // DERIVATIVE: Copyright (c) 2021 Marais Rossouw <hi@marais.io>
    // See: https://github.com/maraisr/meros/blob/219fe95/src/browser.ts

    const executeIncrementalFetch = (onResult, operation, response) => {
      // NOTE: Guarding against fetch polyfills here
      const contentType = response.headers && response.headers.get('Content-Type') || '';

      if (/text\//i.test(contentType)) {
        return response.text().then(text => {
          onResult(makeErrorResult(operation, new Error(text), response));
        });
      } else if (!/multipart\/mixed/i.test(contentType)) {
        return response.text().then(payload => {
          onResult(makeResult(operation, JSON.parse(payload), response));
        });
      }

      let boundary = '---';
      const boundaryHeader = contentType.match(boundaryHeaderRe);
      if (boundaryHeader) boundary = '--' + boundaryHeader[1];
      let read;

      let cancel = () => {
        /*noop*/
      };

      if (response[Symbol.asyncIterator]) {
        const iterator = response[Symbol.asyncIterator]();
        read = iterator.next.bind(iterator);
      } else if ('body' in response && response.body) {
        const reader = response.body.getReader();

        cancel = () => reader.cancel();

        read = () => reader.read();
      } else {
        throw new TypeError('Streaming requests unsupported');
      }

      let buffer = '';
      let isPreamble = true;
      let nextResult = null;
      let prevResult = null;

      function next(data) {
        if (!data.done) {
          const chunk = toString(data.value);
          let boundaryIndex = chunk.indexOf(boundary);

          if (boundaryIndex > -1) {
            boundaryIndex += buffer.length;
          } else {
            boundaryIndex = buffer.indexOf(boundary);
          }

          buffer += chunk;

          while (boundaryIndex > -1) {
            const current = buffer.slice(0, boundaryIndex);
            const next = buffer.slice(boundaryIndex + boundary.length);

            if (isPreamble) {
              isPreamble = false;
            } else {
              const headersEnd = current.indexOf('\r\n\r\n') + 4;
              const headers = current.slice(0, headersEnd);
              const body = current.slice(headersEnd, current.lastIndexOf('\r\n'));
              let payload;

              if (jsonHeaderRe.test(headers)) {
                try {
                  payload = JSON.parse(body);
                  nextResult = prevResult = prevResult ? mergeResultPatch(prevResult, payload, response) : makeResult(operation, payload, response);
                } catch (_error) {}
              }

              if (next.slice(0, 2) === '--' || payload && !payload.hasNext) {
                if (!prevResult) return onResult(makeResult(operation, {}, response));
                break;
              }
            }

            buffer = next;
            boundaryIndex = buffer.indexOf(boundary);
          }
        } else {
          hasResults = true;
        }

        if (nextResult) {
          onResult(nextResult);
          nextResult = null;
        }

        if (!data.done && (!prevResult || prevResult.hasNext)) {
          return read().then(next);
        }
      }

      return read().then(next).finally(cancel);
    };

    let ended = false;
    let statusNotOk = false;
    let response;
    Promise.resolve().then(() => {
      if (ended) return;
      return (fetcher || fetch)(url, fetchOptions);
    }).then(_response => {
      if (!_response) return;
      response = _response;
      statusNotOk = response.status < 200 || response.status >= maxStatus;
      return executeIncrementalFetch(next, operation, response);
    }).then(complete).catch(error => {
      if (hasResults) {
        throw error;
      }

      const result = makeErrorResult(operation, statusNotOk ? response.statusText ? new Error(response.statusText) : error : error, response);
      next(result);
      complete();
    });
    return () => {
      ended = true;

      if (abortController) {
        abortController.abort();
      }
    };
  });
};

exports.CombinedError = CombinedError;
exports.createRequest = createRequest;
exports.getOperationName = getOperationName;
exports.getOperationType = getOperationType;
exports.keyDocument = keyDocument;
exports.makeErrorResult = makeErrorResult;
exports.makeFetchBody = makeFetchBody;
exports.makeFetchOptions = makeFetchOptions;
exports.makeFetchSource = makeFetchSource;
exports.makeFetchURL = makeFetchURL;
exports.makeResult = makeResult;
exports.mergeResultPatch = mergeResultPatch;
exports.stringifyDocument = stringifyDocument;
exports.stringifyVariables = stringifyVariables;
//# sourceMappingURL=a8025a43.js.map
