Object.defineProperty(exports, '__esModule', {
  value: true
});

var graphql = require('graphql');

var fetchSource = require('./a8025a43.js');

var wonka = require('wonka');

const collectTypes = (obj, types) => {
  if (Array.isArray(obj)) {
    for (const item of obj) collectTypes(item, types);
  } else if (typeof obj === 'object' && obj !== null) {
    for (const key in obj) {
      if (key === '__typename' && typeof obj[key] === 'string') {
        types.add(obj[key]);
      } else {
        collectTypes(obj[key], types);
      }
    }
  }

  return types;
};

const collectTypesFromResponse = response => [...collectTypes(response, new Set())];

const formatNode = node => {
  if (!node.selectionSet) return node;

  for (const selection of node.selectionSet.selections) if (selection.kind === graphql.Kind.FIELD && selection.name.value === '__typename' && !selection.alias) return node;

  return { ...node,
    selectionSet: { ...node.selectionSet,
      selections: [...node.selectionSet.selections, {
        kind: graphql.Kind.FIELD,
        name: {
          kind: graphql.Kind.NAME,
          value: '__typename'
        }
      }]
    }
  };
};

const formattedDocs = new Map();

const formatDocument = node => {
  const query = fetchSource.keyDocument(node);
  let result = formattedDocs.get(query.__key);

  if (!result) {
    result = graphql.visit(query, {
      Field: formatNode,
      InlineFragment: formatNode
    }); // Ensure that the hash of the resulting document won't suddenly change
    // we are marking __key as non-enumerable so when external exchanges use visit
    // to manipulate a document we won't restore the previous query due to the __key
    // property.

    Object.defineProperty(result, '__key', {
      value: query.__key,
      enumerable: false
    });
    formattedDocs.set(query.__key, result);
  }

  return result;
};

const maskTypename = data => {
  if (!data || typeof data !== 'object') {
    return data;
  } else if (Array.isArray(data)) {
    return data.map(maskTypename);
  } else if (data && typeof data === 'object' && '__typename' in data) {
    const acc = {};

    for (const key in data) {
      if (key === '__typename') {
        Object.defineProperty(acc, '__typename', {
          enumerable: false,
          value: data.__typename
        });
      } else {
        acc[key] = maskTypename(data[key]);
      }
    }

    return acc;
  } else {
    return data;
  }
};

function withPromise(source$) {
  source$.toPromise = () => {
    return new Promise(resolve => {
      const subscription = wonka.subscribe(result => {
        if (!result.stale && !result.hasNext) {
          Promise.resolve().then(() => {
            subscription.unsubscribe();
            resolve(result);
          });
        }
      })(source$);
    });
  };

  return source$;
}

function makeOperation(kind, request, context) {
  if (!context) context = request.context;
  return {
    key: request.key,
    query: request.query,
    variables: request.variables,
    kind,
    context
  };
}
/** Spreads the provided metadata to the source operation's meta property in context.  */


const addMetadata = (operation, meta) => {
  return makeOperation(operation.kind, operation, { ...operation.context,
    meta: { ...operation.context.meta,
      ...meta
    }
  });
};

const noop = () => {
  /* noop */
};

const applyDefinitions = (fragmentNames, target, source) => {
  for (const definition of source) {
    if (definition.kind === graphql.Kind.FRAGMENT_DEFINITION) {
      const name = definition.name.value;
      const value = fetchSource.stringifyDocument(definition); // Fragments will be deduplicated according to this Map

      if (!fragmentNames.has(name)) {
        fragmentNames.set(name, value);
        target.push(definition);
      } else if (process.env.NODE_ENV !== 'production' && fragmentNames.get(name) !== value) {
        // Fragments with the same names is expected to have the same contents
        console.warn('[WARNING: Duplicate Fragment] A fragment with name `' + name + '` already exists in this document.\n' + 'While fragment names may not be unique across your source, each name must be unique per document.');
      }
    } else {
      target.push(definition);
    }
  }
};

function
/* arguments */
gql() {
  const fragmentNames = new Map();
  const definitions = [];
  const interpolations = []; // Apply the entire tagged template body's definitions

  let body = Array.isArray(arguments[0]) ? arguments[0][0] : arguments[0] || '';

  for (let i = 1; i < arguments.length; i++) {
    const value = arguments[i];

    if (value && value.definitions) {
      interpolations.push(...value.definitions);
    } else {
      body += value;
    }

    body += arguments[0][i];
  } // Apply the tag's body definitions


  applyDefinitions(fragmentNames, definitions, fetchSource.keyDocument(body).definitions); // Copy over each interpolated document's definitions

  applyDefinitions(fragmentNames, definitions, interpolations);
  return fetchSource.keyDocument({
    kind: graphql.Kind.DOCUMENT,
    definitions
  });
}
/* eslint-disable @typescript-eslint/no-use-before-define */


const shouldSkip = ({
  kind
}) => kind !== 'mutation' && kind !== 'query';

const cacheExchange = ({
  forward,
  client,
  dispatchDebug
}) => {
  const resultCache = new Map();
  const operationCache = new Map(); // Adds unique typenames to query (for invalidating cache entries)

  const mapTypeNames = operation => {
    const formattedOperation = makeOperation(operation.kind, operation);
    formattedOperation.query = formatDocument(operation.query);
    return formattedOperation;
  };

  const isOperationCached = operation => {
    const {
      key,
      kind,
      context: {
        requestPolicy
      }
    } = operation;
    return kind === 'query' && requestPolicy !== 'network-only' && (requestPolicy === 'cache-only' || resultCache.has(key));
  };

  return ops$ => {
    const sharedOps$ = wonka.share(ops$);
    const cachedOps$ = wonka.map(operation => {
      const cachedResult = resultCache.get(operation.key);
      process.env.NODE_ENV !== 'production' ? dispatchDebug({
        operation,
        ...(cachedResult ? {
          type: 'cacheHit',
          message: 'The result was successfully retried from the cache'
        } : {
          type: 'cacheMiss',
          message: 'The result could not be retrieved from the cache'
        }),
        "source": "cacheExchange"
      }) : undefined;
      const result = { ...cachedResult,
        operation: addMetadata(operation, {
          cacheOutcome: cachedResult ? 'hit' : 'miss'
        })
      };

      if (operation.context.requestPolicy === 'cache-and-network') {
        result.stale = true;
        reexecuteOperation(client, operation);
      }

      return result;
    })(wonka.filter(op => !shouldSkip(op) && isOperationCached(op))(sharedOps$));
    const forwardedOps$ = wonka.tap(response => {
      let {
        operation
      } = response;
      if (!operation) return;
      const typenames = collectTypesFromResponse(response.data).concat(operation.context.additionalTypenames || []); // Invalidates the cache given a mutation's response

      if (response.operation.kind === 'mutation') {
        const pendingOperations = new Set();
        process.env.NODE_ENV !== 'production' ? dispatchDebug({
          type: 'cacheInvalidation',
          message: `The following typenames have been invalidated: ${typenames}`,
          operation,
          data: {
            typenames,
            response
          },
          "source": "cacheExchange"
        }) : undefined;

        for (let i = 0; i < typenames.length; i++) {
          const typeName = typenames[i];
          let operations = operationCache.get(typeName);
          if (!operations) operationCache.set(typeName, operations = new Set());

          for (const key of operations.values()) pendingOperations.add(key);

          operations.clear();
        }

        for (const key of pendingOperations.values()) {
          if (resultCache.has(key)) {
            operation = resultCache.get(key).operation;
            resultCache.delete(key);
            reexecuteOperation(client, operation);
          }
        }
      } else if (operation.kind === 'query' && response.data) {
        resultCache.set(operation.key, response);

        for (let i = 0; i < typenames.length; i++) {
          const typeName = typenames[i];
          let operations = operationCache.get(typeName);
          if (!operations) operationCache.set(typeName, operations = new Set());
          operations.add(operation.key);
        }
      }
    })(forward(wonka.filter(op => op.kind !== 'query' || op.context.requestPolicy !== 'cache-only')(wonka.map(op => addMetadata(op, {
      cacheOutcome: 'miss'
    }))(wonka.merge([wonka.map(mapTypeNames)(wonka.filter(op => !shouldSkip(op) && !isOperationCached(op))(sharedOps$)), wonka.filter(op => shouldSkip(op))(sharedOps$)])))));
    return wonka.merge([cachedOps$, forwardedOps$]);
  };
}; // Reexecutes a given operation with the default requestPolicy


const reexecuteOperation = (client, operation) => {
  return client.reexecuteOperation(makeOperation(operation.kind, operation, { ...operation.context,
    requestPolicy: 'network-only'
  }));
};
/** Serialize an OperationResult to plain JSON */


const serializeResult = ({
  hasNext,
  data,
  extensions,
  error
}, includeExtensions) => {
  const result = {};
  if (data !== undefined) result.data = JSON.stringify(data);

  if (includeExtensions && extensions !== undefined) {
    result.extensions = JSON.stringify(extensions);
  }

  if (hasNext) result.hasNext = true;

  if (error) {
    result.error = {
      graphQLErrors: error.graphQLErrors.map(error => {
        if (!error.path && !error.extensions) return error.message;
        return {
          message: error.message,
          path: error.path,
          extensions: error.extensions
        };
      })
    };

    if (error.networkError) {
      result.error.networkError = '' + error.networkError;
    }
  }

  return result;
};
/** Deserialize plain JSON to an OperationResult */


const deserializeResult = (operation, result, includeExtensions) => ({
  operation,
  data: result.data ? JSON.parse(result.data) : undefined,
  extensions: includeExtensions && result.extensions ? JSON.parse(result.extensions) : undefined,
  error: result.error ? new fetchSource.CombinedError({
    networkError: result.error.networkError ? new Error(result.error.networkError) : undefined,
    graphQLErrors: result.error.graphQLErrors
  }) : undefined,
  hasNext: result.hasNext
});

const revalidated = new Set();
/** The ssrExchange can be created to capture data during SSR and also to rehydrate it on the client */

const ssrExchange = (params = {}) => {
  const staleWhileRevalidate = !!params.staleWhileRevalidate;
  const includeExtensions = !!params.includeExtensions;
  const data = {}; // On the client-side, we delete results from the cache as they're resolved
  // this is delayed so that concurrent queries don't delete each other's data

  const invalidateQueue = [];

  const invalidate = result => {
    invalidateQueue.push(result.operation.key);

    if (invalidateQueue.length === 1) {
      Promise.resolve().then(() => {
        let key;

        while (key = invalidateQueue.shift()) {
          data[key] = null;
        }
      });
    }
  }; // The SSR Exchange is a temporary cache that can populate results into data for suspense
  // On the client it can be used to retrieve these temporary results from a rehydrated cache


  const ssr = ({
    client,
    forward
  }) => ops$ => {
    // params.isClient tells us whether we're on the client-side
    // By default we assume that we're on the client if suspense-mode is disabled
    const isClient = params && typeof params.isClient === 'boolean' ? !!params.isClient : !client.suspense;
    const sharedOps$ = wonka.share(ops$);
    let forwardedOps$ = forward(wonka.filter(operation => !data[operation.key] || !!data[operation.key].hasNext)(sharedOps$)); // NOTE: Since below we might delete the cached entry after accessing
    // it once, cachedOps$ needs to be merged after forwardedOps$

    let cachedOps$ = wonka.map(op => {
      const serialized = data[op.key];
      const result = deserializeResult(op, serialized, includeExtensions);

      if (staleWhileRevalidate && !revalidated.has(op.key)) {
        result.stale = true;
        revalidated.add(op.key);
        reexecuteOperation(client, op);
      }

      return result;
    })(wonka.filter(operation => !!data[operation.key] && operation.context.requestPolicy !== 'network-only')(sharedOps$));

    if (!isClient) {
      // On the server we cache results in the cache as they're resolved
      forwardedOps$ = wonka.tap(result => {
        const {
          operation
        } = result;

        if (operation.kind !== 'mutation') {
          const serialized = serializeResult(result, includeExtensions);
          data[operation.key] = serialized;
        }
      })(forwardedOps$);
    } else {
      // On the client we delete results from the cache as they're resolved
      cachedOps$ = wonka.tap(invalidate)(cachedOps$);
    }

    return wonka.merge([forwardedOps$, cachedOps$]);
  };

  ssr.restoreData = restore => {
    for (const key in restore) {
      // We only restore data that hasn't been previously invalidated
      if (data[key] !== null) {
        data[key] = restore[key];
      }
    }
  };

  ssr.extractData = () => {
    const result = {};

    for (const key in data) if (data[key] != null) result[key] = data[key];

    return result;
  };

  if (params && params.initialState) {
    ssr.restoreData(params.initialState);
  }

  return ssr;
};

const subscriptionExchange = ({
  forwardSubscription,
  enableAllOperations,
  isSubscriptionOperation
}) => ({
  client,
  forward
}) => {
  const createSubscriptionSource = operation => {
    // This excludes the query's name as a field although subscription-transport-ws does accept it since it's optional
    const observableish = forwardSubscription({
      key: operation.key.toString(36),
      query: graphql.print(operation.query),
      variables: operation.variables,
      context: { ...operation.context
      }
    });
    return wonka.make(({
      next,
      complete
    }) => {
      let isComplete = false;
      let sub;
      Promise.resolve().then(() => {
        if (isComplete) return;
        sub = observableish.subscribe({
          next: result => next(fetchSource.makeResult(operation, result)),
          error: err => next(fetchSource.makeErrorResult(operation, err)),
          complete: () => {
            if (!isComplete) {
              isComplete = true;

              if (operation.kind === 'subscription') {
                client.reexecuteOperation(makeOperation('teardown', operation, operation.context));
              }

              complete();
            }
          }
        });
      });
      return () => {
        isComplete = true;
        if (sub) sub.unsubscribe();
      };
    });
  };

  const isSubscriptionOperationFn = isSubscriptionOperation || (operation => {
    const {
      kind
    } = operation;
    return kind === 'subscription' || !!enableAllOperations && (kind === 'query' || kind === 'mutation');
  });

  return ops$ => {
    const sharedOps$ = wonka.share(ops$);
    const subscriptionResults$ = wonka.mergeMap(operation => {
      const {
        key
      } = operation;
      const teardown$ = wonka.filter(op => op.kind === 'teardown' && op.key === key)(sharedOps$);
      return wonka.takeUntil(teardown$)(createSubscriptionSource(operation));
    })(wonka.filter(isSubscriptionOperationFn)(sharedOps$));
    const forward$ = forward(wonka.filter(op => !isSubscriptionOperationFn(op))(sharedOps$));
    return wonka.merge([subscriptionResults$, forward$]);
  };
};

const debugExchange = ({
  forward
}) => {
  if (process.env.NODE_ENV === 'production') {
    return ops$ => forward(ops$);
  } else {
    return ops$ => wonka.tap(result => // eslint-disable-next-line no-console
    console.log('[Exchange debug]: Completed operation: ', result))(forward( // eslint-disable-next-line no-console
    wonka.tap(op => console.log('[Exchange debug]: Incoming operation: ', op))(ops$)));
  }
};
/** A default exchange for debouncing GraphQL requests. */


const dedupExchange = ({
  forward,
  dispatchDebug
}) => {
  const inFlightKeys = new Set();

  const filterIncomingOperation = operation => {
    const {
      key,
      kind
    } = operation;

    if (kind === 'teardown' || kind === 'mutation') {
      inFlightKeys.delete(key);
      return true;
    }

    const isInFlight = inFlightKeys.has(key);
    inFlightKeys.add(key);

    if (isInFlight) {
      process.env.NODE_ENV !== 'production' ? dispatchDebug({
        type: 'dedup',
        message: 'An operation has been deduped.',
        operation,
        "source": "dedupExchange"
      }) : undefined;
    }

    return !isInFlight;
  };

  const afterOperationResult = ({
    operation,
    hasNext
  }) => {
    if (!hasNext) {
      inFlightKeys.delete(operation.key);
    }
  };

  return ops$ => {
    const forward$ = wonka.filter(filterIncomingOperation)(ops$);
    return wonka.tap(afterOperationResult)(forward(forward$));
  };
};
/* eslint-disable @typescript-eslint/no-use-before-define */

/** A default exchange for fetching GraphQL requests. */


const fetchExchange = ({
  forward,
  dispatchDebug
}) => {
  return ops$ => {
    const sharedOps$ = wonka.share(ops$);
    const fetchResults$ = wonka.mergeMap(operation => {
      const {
        key
      } = operation;
      const body = fetchSource.makeFetchBody(operation);
      const url = fetchSource.makeFetchURL(operation, body);
      const fetchOptions = fetchSource.makeFetchOptions(operation, body);
      process.env.NODE_ENV !== 'production' ? dispatchDebug({
        type: 'fetchRequest',
        message: 'A fetch request is being executed.',
        operation,
        data: {
          url,
          fetchOptions
        },
        "source": "fetchExchange"
      }) : undefined;
      const source = wonka.takeUntil(wonka.filter(op => op.kind === 'teardown' && op.key === key)(sharedOps$))(fetchSource.makeFetchSource(operation, url, fetchOptions));

      if (process.env.NODE_ENV !== 'production') {
        return wonka.onPush(result => {
          const error = !result.data ? result.error : undefined;
          process.env.NODE_ENV !== 'production' ? dispatchDebug({
            type: error ? 'fetchError' : 'fetchSuccess',
            message: `A ${error ? 'failed' : 'successful'} fetch response has been returned.`,
            operation,
            data: {
              url,
              fetchOptions,
              value: error || result
            },
            "source": "fetchExchange"
          }) : undefined;
        })(source);
      }

      return source;
    })(wonka.filter(operation => {
      return operation.kind === 'query' || operation.kind === 'mutation';
    })(sharedOps$));
    const forward$ = forward(wonka.filter(operation => {
      return operation.kind !== 'query' && operation.kind !== 'mutation';
    })(sharedOps$));
    return wonka.merge([fetchResults$, forward$]);
  };
};
/** This is always the last exchange in the chain; No operation should ever reach it */


const fallbackExchange = ({
  dispatchDebug
}) => ops$ =>
/* All operations that skipped through the entire exchange chain should be filtered from the output */
wonka.filter(() => false)(wonka.tap(operation => {
  if (operation.kind !== 'teardown' && process.env.NODE_ENV !== 'production') {
    const message = `No exchange has handled operations of kind "${operation.kind}". Check whether you've added an exchange responsible for these operations.`;
    process.env.NODE_ENV !== 'production' ? dispatchDebug({
      type: 'fallbackCatch',
      message,
      operation,
      "source": "fallbackExchange"
    }) : undefined;
    console.warn(message);
  }
})(ops$));

const fallbackExchangeIO = fallbackExchange({
  dispatchDebug: noop
});
/** This composes an array of Exchanges into a single ExchangeIO function */

const composeExchanges = exchanges => ({
  client,
  forward,
  dispatchDebug
}) => exchanges.reduceRight((forward, exchange) => exchange({
  client,
  forward,

  dispatchDebug(event) {
    process.env.NODE_ENV !== 'production' ? dispatchDebug({
      timestamp: Date.now(),
      source: exchange.name,
      ...event,
      "source": "fetchExchange"
    }) : undefined;
  }

}), forward);

const errorExchange = ({
  onError
}) => ({
  forward
}) => ops$ => {
  return wonka.tap(({
    error,
    operation
  }) => {
    if (error) {
      onError(error, operation);
    }
  })(forward(ops$));
};

const defaultExchanges = [dedupExchange, cacheExchange, fetchExchange];
/* eslint-disable @typescript-eslint/no-use-before-define */

const Client = function Client(opts) {
  if (process.env.NODE_ENV !== 'production' && !opts.url) {
    throw new Error('You are creating an urql-client without a url.');
  }

  const replays = new Map();
  const active = new Map();
  const queue = [];
  const baseOpts = {
    url: opts.url,
    fetchOptions: opts.fetchOptions,
    fetch: opts.fetch,
    preferGetMethod: !!opts.preferGetMethod,
    requestPolicy: opts.requestPolicy || 'cache-first'
  }; // This subject forms the input of operations; executeOperation may be
  // called to dispatch a new operation on the subject

  const {
    source: operations$,
    next: nextOperation
  } = wonka.makeSubject(); // We define a queued dispatcher on the subject, which empties the queue when it's
  // activated to allow `reexecuteOperation` to be trampoline-scheduled

  let isOperationBatchActive = false;

  function dispatchOperation(operation) {
    if (operation) nextOperation(operation);

    if (!isOperationBatchActive) {
      isOperationBatchActive = true;

      while (isOperationBatchActive && (operation = queue.shift())) nextOperation(operation);

      isOperationBatchActive = false;
    }
  }
  /** Defines how result streams are created */


  const makeResultSource = operation => {
    let result$ = wonka.filter(res => {
      return res.operation.kind === operation.kind && res.operation.key === operation.key && (!res.operation.context._instance || res.operation.context._instance === operation.context._instance);
    })(results$); // Mask typename properties if the option for it is turned on

    if (opts.maskTypename) {
      result$ = wonka.map(res => ({ ...res,
        data: maskTypename(res.data)
      }))(result$);
    } // A mutation is always limited to just a single result and is never shared


    if (operation.kind === 'mutation') {
      return wonka.take(1)(wonka.onStart(() => nextOperation(operation))(result$));
    }

    const source = wonka.share(wonka.onEnd(() => {
      // Delete the active operation handle
      replays.delete(operation.key);
      active.delete(operation.key); // Delete all queued up operations of the same key on end

      for (let i = queue.length - 1; i >= 0; i--) if (queue[i].key === operation.key) queue.splice(i, 1); // Dispatch a teardown signal for the stopped operation


      nextOperation(makeOperation('teardown', operation, operation.context));
    })(wonka.onPush(result => {
      replays.set(operation.key, result);
    })(wonka.switchMap(result => {
      if (operation.kind !== 'query' || result.stale) {
        return wonka.fromValue(result);
      }

      return wonka.merge([wonka.fromValue(result), // Mark a result as stale when a new operation is sent for it
      wonka.map(() => ({ ...result,
        stale: true
      }))(wonka.take(1)(wonka.filter(op => op.kind === 'query' && op.key === operation.key && op.context.requestPolicy !== 'cache-only')(operations$)))]);
    })( // End the results stream when an active teardown event is sent
    wonka.takeUntil(wonka.filter(op => op.kind === 'teardown' && op.key === operation.key)(operations$))(result$)))));
    return source;
  };

  const instance = this instanceof Client ? this : Object.create(Client.prototype);
  const client = Object.assign(instance, {
    suspense: !!opts.suspense,
    operations$,

    reexecuteOperation(operation) {
      // Reexecute operation only if any subscribers are still subscribed to the
      // operation's exchange results
      if (operation.kind === 'mutation' || active.has(operation.key)) {
        queue.push(operation);
        Promise.resolve().then(dispatchOperation);
      }
    },

    createRequestOperation(kind, request, opts) {
      if (!opts) opts = {};
      const requestOperationType = fetchSource.getOperationType(request.query);

      if (process.env.NODE_ENV !== 'production' && kind !== 'teardown' && requestOperationType !== kind) {
        throw new Error(`Expected operation of type "${kind}" but found "${requestOperationType}"`);
      }

      return makeOperation(kind, request, {
        _instance: kind === 'mutation' ? [] : undefined,
        ...baseOpts,
        ...opts,
        suspense: opts.suspense || opts.suspense !== false && client.suspense
      });
    },

    executeRequestOperation(operation) {
      if (operation.kind === 'mutation') {
        return makeResultSource(operation);
      }

      return wonka.make(observer => {
        let source = active.get(operation.key);

        if (!source) {
          active.set(operation.key, source = makeResultSource(operation));
        }

        const isNetworkOperation = operation.context.requestPolicy === 'cache-and-network' || operation.context.requestPolicy === 'network-only';
        return wonka.subscribe(observer.next)(wonka.onEnd(() => {
          isOperationBatchActive = false;
          observer.complete();
        })(wonka.onStart(() => {
          const prevReplay = replays.get(operation.key);

          if (operation.kind === 'subscription') {
            return dispatchOperation(operation);
          } else if (isNetworkOperation) {
            dispatchOperation(operation);
          }

          if (prevReplay != null && prevReplay === replays.get(operation.key)) {
            observer.next(isNetworkOperation ? { ...prevReplay,
              stale: true
            } : prevReplay);
          } else if (!isNetworkOperation) {
            dispatchOperation(operation);
          }
        })(source))).unsubscribe;
      });
    },

    executeQuery(query, opts) {
      const operation = client.createRequestOperation('query', query, opts);
      return client.executeRequestOperation(operation);
    },

    executeSubscription(query, opts) {
      const operation = client.createRequestOperation('subscription', query, opts);
      return client.executeRequestOperation(operation);
    },

    executeMutation(query, opts) {
      const operation = client.createRequestOperation('mutation', query, opts);
      return client.executeRequestOperation(operation);
    },

    query(query, variables, context) {
      if (!context || typeof context.suspense !== 'boolean') {
        context = { ...context,
          suspense: false
        };
      }

      return withPromise(client.executeQuery(fetchSource.createRequest(query, variables), context));
    },

    readQuery(query, variables, context) {
      let result = null;
      wonka.subscribe(res => {
        result = res;
      })(client.query(query, variables, context)).unsubscribe();
      return result;
    },

    subscription(query, variables, context) {
      return client.executeSubscription(fetchSource.createRequest(query, variables), context);
    },

    mutation(query, variables, context) {
      return withPromise(client.executeMutation(fetchSource.createRequest(query, variables), context));
    }

  });
  let dispatchDebug = noop;

  if (process.env.NODE_ENV !== 'production') {
    const {
      next,
      source
    } = wonka.makeSubject();

    client.subscribeToDebugTarget = onEvent => wonka.subscribe(onEvent)(source);

    dispatchDebug = next;
  }

  const exchanges = opts.exchanges !== undefined ? opts.exchanges : defaultExchanges; // All exchange are composed into a single one and are called using the constructed client
  // and the fallback exchange stream

  const composedExchange = composeExchanges(exchanges); // All exchanges receive inputs using which they can forward operations to the next exchange
  // and receive a stream of results in return, access the client, or dispatch debugging events
  // All operations then run through the Exchange IOs in a pipeline-like fashion

  const results$ = wonka.share(composedExchange({
    client,
    dispatchDebug,
    forward: fallbackExchange({
      dispatchDebug
    })
  })(operations$)); // Prevent the `results$` exchange pipeline from being closed by active
  // cancellations cascading up from components

  wonka.publish(results$);
  return client;
};

const createClient = Client;
exports.CombinedError = fetchSource.CombinedError;
exports.createRequest = fetchSource.createRequest;
exports.getOperationName = fetchSource.getOperationName;
exports.makeErrorResult = fetchSource.makeErrorResult;
exports.makeResult = fetchSource.makeResult;
exports.mergeResultPatch = fetchSource.mergeResultPatch;
exports.stringifyVariables = fetchSource.stringifyVariables;
exports.Client = Client;
exports.cacheExchange = cacheExchange;
exports.composeExchanges = composeExchanges;
exports.createClient = createClient;
exports.debugExchange = debugExchange;
exports.dedupExchange = dedupExchange;
exports.defaultExchanges = defaultExchanges;
exports.errorExchange = errorExchange;
exports.fallbackExchangeIO = fallbackExchangeIO;
exports.fetchExchange = fetchExchange;
exports.formatDocument = formatDocument;
exports.gql = gql;
exports.makeOperation = makeOperation;
exports.maskTypename = maskTypename;
exports.ssrExchange = ssrExchange;
exports.subscriptionExchange = subscriptionExchange;
//# sourceMappingURL=urql-core.js.map
